{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analisis Sentimen pada Aplikasi My Telkomsel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qpW2CfFNQmd"
      },
      "source": [
        "## 1. Import Library dan Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QonMZC10Pf6O"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\khair\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\khair\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\khair\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # Pandas untuk manipulasi dan analisis data\n",
        "pd.options.mode.chained_assignment = None  # Menonaktifkan peringatan chaining\n",
        "import numpy as np  # NumPy untuk komputasi numerik\n",
        "seed = 0\n",
        "np.random.seed(seed)  # Mengatur seed untuk reproduktibilitas\n",
        "import matplotlib.pyplot as plt  # Matplotlib untuk visualisasi data\n",
        "import seaborn as sns  # Seaborn untuk visualisasi data statistik, mengatur gaya visualisasi\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "import unicodedata # Modul untuk bekerja dengan Unicode\n",
        "import requests # Modul yang memungkinkan untuk mengirim htttp request\n",
        "import os # Modul untuk pekerja terkait os seperti manajemen file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks\n",
        "\n",
        "from Sastrawi.Stemmer import StemmerFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks\n",
        "\n",
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stopwords) dalam berbagai bahasa.\n",
        "nltk.download('punkt_tab') # Download the punkt_tab data package\n",
        "pd.options.mode.copy_on_write = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import RMSprop, AdamW, Adam\n",
        "from sklearn.model_selection import train_test_split "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed, RetryCallState\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "app_reviews_df = pd.read_csv('app_reviews.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EikX2JI5Niga"
      },
      "source": [
        "## 2. Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>appVersion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bb582a94-9844-40aa-8c97-506e07c22fb7</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>Jujur pake Shopee ini baguss banget sebenernya...</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>3.42.24</td>\n",
              "      <td>2025-01-21 20:19:08</td>\n",
              "      <td>Hai kak, mohon maaf atas ketidaknyamanan nya. ...</td>\n",
              "      <td>2025-01-21 21:18:24</td>\n",
              "      <td>3.42.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d8474dc1-da09-4605-9aab-de73f1d61dbe</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>Terus terang saya suka sekali belanja di shope...</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>3.42.24</td>\n",
              "      <td>2025-01-21 05:13:42</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.42.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63dbc9c4-2da7-4825-b335-2a5a1e1575de</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>Aplikasinya bagus, mudah dipahami. Seeing bela...</td>\n",
              "      <td>5</td>\n",
              "      <td>309</td>\n",
              "      <td>3.42.24</td>\n",
              "      <td>2025-01-20 09:29:58</td>\n",
              "      <td>Hi kak, maaf ya udh buat kamu ga nyaman. Terka...</td>\n",
              "      <td>2023-02-07 16:24:08</td>\n",
              "      <td>3.42.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               reviewId         userName  \\\n",
              "0  bb582a94-9844-40aa-8c97-506e07c22fb7  Pengguna Google   \n",
              "1  d8474dc1-da09-4605-9aab-de73f1d61dbe  Pengguna Google   \n",
              "2  63dbc9c4-2da7-4825-b335-2a5a1e1575de  Pengguna Google   \n",
              "\n",
              "                                           userImage  \\\n",
              "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "\n",
              "                                             content  score  thumbsUpCount  \\\n",
              "0  Jujur pake Shopee ini baguss banget sebenernya...      2             20   \n",
              "1  Terus terang saya suka sekali belanja di shope...      3             17   \n",
              "2  Aplikasinya bagus, mudah dipahami. Seeing bela...      5            309   \n",
              "\n",
              "  reviewCreatedVersion                   at  \\\n",
              "0              3.42.24  2025-01-21 20:19:08   \n",
              "1              3.42.24  2025-01-21 05:13:42   \n",
              "2              3.42.24  2025-01-20 09:29:58   \n",
              "\n",
              "                                        replyContent            repliedAt  \\\n",
              "0  Hai kak, mohon maaf atas ketidaknyamanan nya. ...  2025-01-21 21:18:24   \n",
              "1                                                NaN                  NaN   \n",
              "2  Hi kak, maaf ya udh buat kamu ga nyaman. Terka...  2023-02-07 16:24:08   \n",
              "\n",
              "  appVersion  \n",
              "0    3.42.24  \n",
              "1    3.42.24  \n",
              "2    3.42.24  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app_reviews_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEiGur1JNm0j",
        "outputId": "322103cf-1b0d-4559-f64d-ac8b779ee355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              3000 non-null   object\n",
            " 1   userName              3000 non-null   object\n",
            " 2   userImage             3000 non-null   object\n",
            " 3   content               3000 non-null   object\n",
            " 4   score                 3000 non-null   int64 \n",
            " 5   thumbsUpCount         3000 non-null   int64 \n",
            " 6   reviewCreatedVersion  3000 non-null   object\n",
            " 7   at                    3000 non-null   object\n",
            " 8   replyContent          2808 non-null   object\n",
            " 9   repliedAt             2808 non-null   object\n",
            " 10  appVersion            3000 non-null   object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 257.9+ KB\n"
          ]
        }
      ],
      "source": [
        "app_reviews_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4wgVP-ErODzc"
      },
      "outputs": [],
      "source": [
        "df = app_reviews_df[['content','score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "RhT8mH3fN0DZ",
        "outputId": "c228e39b-2e73-4ce4-fb90-74d365b800b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "content    0\n",
              "score      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengecek data yang kosong atau hilang\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X-FxGUwhURGK"
      },
      "outputs": [],
      "source": [
        "# Menghapus baris yang memiliki duplikat\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "501j_p1eNYvB"
      },
      "source": [
        "## 3. Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oy1aKNAqNakn"
      },
      "outputs": [],
      "source": [
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
        "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
        "\n",
        "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
        "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
        "    return text\n",
        "\n",
        "def remove_superscripts_and_subscripts(text):\n",
        "    # memfilter karakter yang bukan superscript atau subscript\n",
        "    def is_not_super_or_sub(char):\n",
        "        # Cek kategori Unicode karakter\n",
        "        return not (unicodedata.name(char, \"\").startswith(\"SUPERSCRIPT\") or\n",
        "                    unicodedata.name(char, \"\").startswith(\"SUBSCRIPT\"))\n",
        "\n",
        "    # Filter karakter dari teks\n",
        "    text = ''.join(filter(is_not_super_or_sub, text))\n",
        "    return text\n",
        "\n",
        "def casefoldingText(text): \n",
        "    # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def tokenizingText(text): \n",
        "    # Memecah atau membagi string, teks menjadi daftar token\n",
        "    text = word_tokenize(text)\n",
        "    return text\n",
        "\n",
        "def filteringText(text): \n",
        "    # Menghapus stopwords dalam teks\n",
        "    listStopwords = set(stopwords.words('indonesian'))\n",
        "    listStopwords1 = set(stopwords.words('english'))\n",
        "    listStopwords.update(listStopwords1)\n",
        "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\"])\n",
        "    filtered = []\n",
        "    for txt in text:\n",
        "        if txt not in listStopwords:\n",
        "            filtered.append(txt)\n",
        "    text = filtered\n",
        "    return text\n",
        "\n",
        "def stemmingText(text): \n",
        "    # Mengurangi kata ke bentuk dasarnya yang menghilangkan imbuhan awalan dan akhiran atau ke akar kata\n",
        "    \n",
        "    # Membuat objek stemmer\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    # Memecah teks menjadi daftar kata\n",
        "    words = text.split()\n",
        "\n",
        "    # Menerapkan stemming pada setiap kata dalam daftar\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Menggabungkan kata-kata yang telah distem\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
        "    sentence = ' '.join(word for word in list_words)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# URL file slang words\n",
        "url = \"https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/master/combined_slang_words.txt\"\n",
        "\n",
        "# Mengambil konten file dari URL\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    content = response.text\n",
        "    # Memproses konten ke dalam dictionary\n",
        "    slangwords = {}\n",
        "    for line in content.strip().split(\",\"):\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)  # Memisahkan kata slang dan arti\n",
        "            key = key.strip('{\"}') # Menghilangkan tanda kurung kurawal pada key\n",
        "            value = value.strip('{\"}') # Menghilangkan tanda kurung kurawal pada value\n",
        "            slangwords[key.strip(' \"\\'')] = value.strip(' \"\\'') # Menyimpan pasangan key-value pada dictionary slangwords\n",
        "else:\n",
        "    print(f\"Gagal mengunduh file dari URL. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0mFakJyPzMF",
        "outputId": "d188029d-6086-43f9-d003-886d4b073ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('@', 'di'),\n",
              " ('abis', 'habis'),\n",
              " ('ad', 'ada'),\n",
              " ('adlh', 'adalah'),\n",
              " ('afaik', 'as far as i know')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(slangwords.items())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LKE4VfgVWWmU"
      },
      "outputs": [],
      "source": [
        "def fix_slangwords(text):\n",
        "    # Memperbaiki kata-kata slang dalam teks\n",
        "    words = text.split()\n",
        "    fixed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.lower() in slangwords:\n",
        "            fixed_words.append(slangwords[word.lower()])\n",
        "        else:\n",
        "            fixed_words.append(word)\n",
        "\n",
        "    fixed_text = ' '.join(fixed_words)\n",
        "    return fixed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U9lmfG_3WRyy"
      },
      "outputs": [],
      "source": [
        "# Membersihkan teks dan menyimpannya di kolom 'text_clean'\n",
        "df['text_clean'] = df['content'].apply(cleaningText).apply(remove_superscripts_and_subscripts)\n",
        "\n",
        "# Mengubah huruf dalam teks menjadi huruf kecil dan menyimpannya di 'text_casefoldingText'\n",
        "df['text_casefoldingText'] = df['text_clean'].apply(casefoldingText)\n",
        "\n",
        "# Mengganti kata-kata slang dengan kata-kata standar dan menyimpannya di 'text_slangwords'\n",
        "df['text_slangwords'] = df['text_casefoldingText'].apply(fix_slangwords)\n",
        "\n",
        "# Memecah teks menjadi token (kata-kata) dan menyimpannya di 'text_tokenizingText'\n",
        "df['text_tokenizingText'] = df['text_slangwords'].apply(tokenizingText)\n",
        "\n",
        "# Menghapus kata-kata stop (kata-kata umum) dan menyimpannya di 'text_stopword'\n",
        "df['text_stopword'] = df['text_tokenizingText'].apply(filteringText)\n",
        "\n",
        "# Menggabungkan token-token menjadi kalimat dan menyimpannya di 'text_akhir'\n",
        "df['text_akhir'] = df['text_stopword'].apply(toSentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "NnuFfl_xWse1",
        "outputId": "d4cfe30b-6eb4-43c3-afaf-4c6d277b5c86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_casefoldingText</th>\n",
              "      <th>text_slangwords</th>\n",
              "      <th>text_tokenizingText</th>\n",
              "      <th>text_stopword</th>\n",
              "      <th>text_akhir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jujur pake Shopee ini baguss banget sebenernya...</td>\n",
              "      <td>2</td>\n",
              "      <td>Jujur pake Shopee ini baguss banget sebenernya...</td>\n",
              "      <td>jujur pake shopee ini baguss banget sebenernya...</td>\n",
              "      <td>jujur pakai shopee ini baguss banget sebenerny...</td>\n",
              "      <td>[jujur, pakai, shopee, ini, baguss, banget, se...</td>\n",
              "      <td>[jujur, pakai, shopee, baguss, banget, sebener...</td>\n",
              "      <td>jujur pakai shopee baguss banget sebenernya be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Terus terang saya suka sekali belanja di shope...</td>\n",
              "      <td>3</td>\n",
              "      <td>Terus terang saya suka sekali belanja di shope...</td>\n",
              "      <td>terus terang saya suka sekali belanja di shope...</td>\n",
              "      <td>terus terang saya suka sekali belanja di shope...</td>\n",
              "      <td>[terus, terang, saya, suka, sekali, belanja, d...</td>\n",
              "      <td>[terang, suka, belanja, shopee, kesini, shopee...</td>\n",
              "      <td>terang suka belanja shopee kesini shopee memba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aplikasinya bagus, mudah dipahami. Seeing bela...</td>\n",
              "      <td>5</td>\n",
              "      <td>Aplikasinya bagus mudah dipahami Seeing belanj...</td>\n",
              "      <td>aplikasinya bagus mudah dipahami seeing belanj...</td>\n",
              "      <td>aplikasinya bagus mudah dipahami seeing belanj...</td>\n",
              "      <td>[aplikasinya, bagus, mudah, dipahami, seeing, ...</td>\n",
              "      <td>[aplikasinya, bagus, mudah, dipahami, seeing, ...</td>\n",
              "      <td>aplikasinya bagus mudah dipahami seeing belanj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1. Pesanan cod roksaya dibatalkan sendiri oleh...</td>\n",
              "      <td>3</td>\n",
              "      <td>Pesanan cod roksaya dibatalkan sendiri oleh si...</td>\n",
              "      <td>pesanan cod roksaya dibatalkan sendiri oleh si...</td>\n",
              "      <td>pesanan cod roksaya dibatalkan sendiri oleh si...</td>\n",
              "      <td>[pesanan, cod, roksaya, dibatalkan, sendiri, o...</td>\n",
              "      <td>[pesanan, cod, roksaya, dibatalkan, sistem, me...</td>\n",
              "      <td>pesanan cod roksaya dibatalkan sistem melewati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aplikasi elit benerin bug shopeepay sulit, tia...</td>\n",
              "      <td>2</td>\n",
              "      <td>Aplikasi elit benerin bug shopeepay sulit tiap...</td>\n",
              "      <td>aplikasi elit benerin bug shopeepay sulit tiap...</td>\n",
              "      <td>aplikasi elit benerin bug shopeepay sulit tiap...</td>\n",
              "      <td>[aplikasi, elit, benerin, bug, shopeepay, suli...</td>\n",
              "      <td>[aplikasi, elit, benerin, bug, shopeepay, suli...</td>\n",
              "      <td>aplikasi elit benerin bug shopeepay sulit upda...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  score  \\\n",
              "0  Jujur pake Shopee ini baguss banget sebenernya...      2   \n",
              "1  Terus terang saya suka sekali belanja di shope...      3   \n",
              "2  Aplikasinya bagus, mudah dipahami. Seeing bela...      5   \n",
              "3  1. Pesanan cod roksaya dibatalkan sendiri oleh...      3   \n",
              "4  Aplikasi elit benerin bug shopeepay sulit, tia...      2   \n",
              "\n",
              "                                          text_clean  \\\n",
              "0  Jujur pake Shopee ini baguss banget sebenernya...   \n",
              "1  Terus terang saya suka sekali belanja di shope...   \n",
              "2  Aplikasinya bagus mudah dipahami Seeing belanj...   \n",
              "3  Pesanan cod roksaya dibatalkan sendiri oleh si...   \n",
              "4  Aplikasi elit benerin bug shopeepay sulit tiap...   \n",
              "\n",
              "                                text_casefoldingText  \\\n",
              "0  jujur pake shopee ini baguss banget sebenernya...   \n",
              "1  terus terang saya suka sekali belanja di shope...   \n",
              "2  aplikasinya bagus mudah dipahami seeing belanj...   \n",
              "3  pesanan cod roksaya dibatalkan sendiri oleh si...   \n",
              "4  aplikasi elit benerin bug shopeepay sulit tiap...   \n",
              "\n",
              "                                     text_slangwords  \\\n",
              "0  jujur pakai shopee ini baguss banget sebenerny...   \n",
              "1  terus terang saya suka sekali belanja di shope...   \n",
              "2  aplikasinya bagus mudah dipahami seeing belanj...   \n",
              "3  pesanan cod roksaya dibatalkan sendiri oleh si...   \n",
              "4  aplikasi elit benerin bug shopeepay sulit tiap...   \n",
              "\n",
              "                                 text_tokenizingText  \\\n",
              "0  [jujur, pakai, shopee, ini, baguss, banget, se...   \n",
              "1  [terus, terang, saya, suka, sekali, belanja, d...   \n",
              "2  [aplikasinya, bagus, mudah, dipahami, seeing, ...   \n",
              "3  [pesanan, cod, roksaya, dibatalkan, sendiri, o...   \n",
              "4  [aplikasi, elit, benerin, bug, shopeepay, suli...   \n",
              "\n",
              "                                       text_stopword  \\\n",
              "0  [jujur, pakai, shopee, baguss, banget, sebener...   \n",
              "1  [terang, suka, belanja, shopee, kesini, shopee...   \n",
              "2  [aplikasinya, bagus, mudah, dipahami, seeing, ...   \n",
              "3  [pesanan, cod, roksaya, dibatalkan, sistem, me...   \n",
              "4  [aplikasi, elit, benerin, bug, shopeepay, suli...   \n",
              "\n",
              "                                          text_akhir  \n",
              "0  jujur pakai shopee baguss banget sebenernya be...  \n",
              "1  terang suka belanja shopee kesini shopee memba...  \n",
              "2  aplikasinya bagus mudah dipahami seeing belanj...  \n",
              "3  pesanan cod roksaya dibatalkan sistem melewati...  \n",
              "4  aplikasi elit benerin bug shopeepay sulit upda...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raPDBNb7aI5v"
      },
      "source": [
        "## 4. Labeling Kata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analisis sentimen untuk menentukan polaritas setiap review pada data menggunakan model LLM. Model LLM yang digunakan dikonfigurasikan sedemikian rupa sehingga dapat memberikan analisis yang akurat untuk setiap data di dalam dataset. Model LLM disematkan dengan prompt khusus untuk melakukan tugas analisis sentimen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Membangun Model LLM dengan Tugas Analisis Sentimen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mengekstrak kode API agar bisa menggunakan model LLM\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOllama(model=\"deepseek-r1:1.5b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# llm = ChatGroq(model='llama-3.3-70b-versatile')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_template = \"\"\"\n",
        "APAPUN KUERI YANG DIBERIKAN CUKUP JAWAB DENGAN SATU KATA\n",
        "Kategorikan KUERI menjadi negatif atau positif! CUKUP JAWAB DENGAN SATU KATA ANTARA \n",
        "\\\"positif\\\" DAN \\\"negatif\\\"\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_template),\n",
        "    (\"human\", \"{user_input}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Menyatukan template, model, dan ouput parser dalam satu pipeline\n",
        "sentiment_analysis = prompt_template | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fungsi untuk mem-parsing waktu tunggu dari pesan error\n",
        "def get_wait_time_from_error(error_message):\n",
        "    try:\n",
        "        # Cari pola seperti \"try again in 1m22.142s\"\n",
        "        match = re.search(r\"try again in (\\d+)m(\\d+\\.\\d+)s\", error_message['error']['message'])\n",
        "        if match:\n",
        "            minutes = int(match.group(1))  # Ambil bagian menit\n",
        "            seconds = float(match.group(2))  # Ambil bagian detik\n",
        "            return minutes * 60 + seconds  # Total waktu tunggu dalam detik\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Jika parsing gagal, gunakan waktu tunggu default\n",
        "    return 120  # Default 120 detik\n",
        "\n",
        "# Callback untuk menampilkan error dan waktu tunggu\n",
        "def retry_callback(retry_state: RetryCallState):\n",
        "    error = retry_state.outcome.exception()  # Ambil error dari percobaan terakhir\n",
        "    if error:\n",
        "        error_message = str(error)  # Ubah error menjadi string\n",
        "        wait_time = get_wait_time_from_error(error_message)  # Dapatkan waktu tunggu\n",
        "        print(f\"Attempt {retry_state.attempt_number} failed. Error: {error_message}\")\n",
        "        print(f\"Retrying in {wait_time:.2f} seconds...\")\n",
        "        time.sleep(wait_time)  # Tunggu sebelum mencoba lagi\n",
        "\n",
        "# Dekorator retry dengan callback\n",
        "@retry(\n",
        "    stop=stop_after_attempt(10),  # Maksimal 10 percobaan\n",
        "    wait=wait_fixed(1),  # Waktu tunggu fixed sementara, diabaikan karena manual di callback\n",
        "    after=retry_callback  # Callback untuk menangani retry\n",
        ")\n",
        "def check_polarity(text_input):\n",
        "    try:\n",
        "        # Panggil model untuk analisis sentimen\n",
        "        return sentiment_analysis.invoke({\"user_input\": text_input})\n",
        "    except Exception as e:\n",
        "        # Tangkap error dan lempar kembali untuk ditangani oleh retry\n",
        "        raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<think>\\nOkay, so I need to categorize the query \"KUERI\" as either positive or negative. First, I should understand what \"KUERI\" stands for. From what I know in English, QR codes are used in various applications like technology and media. They can contain data, images, videos, etc., but they don\\'t have a traditional meaning of being something positive or negative.\\n\\nI\\'m not entirely sure how to determine if the query itself is positive or negative. Maybe it\\'s about whether there are any issues related to \"KUERI.\" Since QR codes are commonly used and can be manipulated for different purposes, this might lead to some negative aspects. However, I also know that their security and purposefulness are important in many applications.\\n\\nI\\'m leaning towards thinking that the presence of a QR code is neutral because it\\'s versatile but not inherently positive or negative by itself. It depends on how it\\'s used. So, when someone mentions \"KUERI,\" it could be part of a positive use case where they\\'re creating something tech-savvily, but also part of a negative scenario if they\\'re trying to bypass security or misuse them maliciously.\\n\\nTherefore, I think the answer should state that without context, it\\'s neutral. It could have both sides of the coin depending on the situation.\\n</think>\\n\\nKUERI stands for QR code and is versatile in many applications but does not inherently convey positive or negative intent unless its usage is considered contextually. Therefore, without specific context, \"KUERI\" is considered neutral, as it can be used positively or negatively based on how it\\'s employed.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_input = \"Sangat direkomendasikan!!! saya selalu beli produk ini setiap bulan karena performanya sangat bisa diandalkan\"\n",
        "check_polarity(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Negatif'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_polarity('produk kau ga jelas, menyesal saya beli di toko penipu ini')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:   0%|          | 0/3000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:   6%|▌         | 180/3000 [07:21<6:47:43,  8.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 failed. Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jbefye1nf41bk4v2nwafmptv` service tier `on_demand` on : Limit 100000, Used 100055, Requested 94. Please try again in 2m9.168s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
            "Retrying in 120.00 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:   6%|▌         | 181/3000 [09:31<35:23:34, 45.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 failed. Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jbefye1nf41bk4v2nwafmptv` service tier `on_demand` on : Limit 100000, Used 100067, Requested 73. Please try again in 2m1.583s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
            "Retrying in 120.00 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Rows:   6%|▌         | 182/3000 [11:34<53:40:58, 68.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1 failed. Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jbefye1nf41bk4v2nwafmptv` service tier `on_demand` on : Limit 100000, Used 100058, Requested 118. Please try again in 2m32.59s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
            "Retrying in 120.00 seconds...\n"
          ]
        }
      ],
      "source": [
        "# Pelabelan data berdasarkan model yang telah dibangun\n",
        "tqdm.pandas()\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\"):\n",
        "    if pd.isna(row.get(\"polarity\")):  # Skip jika sudah ada nilai\n",
        "        try:\n",
        "            df.at[idx, \"polarity\"] = check_polarity(row[\"text_akhir\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error at row {idx}: {e}\")\n",
        "            raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "polarity\n",
              "negatif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1473\n",
              "positif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          868\n",
              "Negatif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          154\n",
              "Positif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           66\n",
              "positif.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          11\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ... \n",
              "Berikut analisis sentimennya:\\n\\n- \"tolong\" (positif)\\n- \"shopee kembalikan setelan awal\" (positif)\\n- \"dimana jasa kirimnya\" (netral)\\n- \"pakai jne jnt saja\" (positif)\\n- \"soalnya spx profesional\" (positif)\\n- \"masa kurirnya datang\" (positif)\\n- \"datang kerumah barang pesanan terertur sendiri\" (negatif)\\n- \"padahal retur loh\" (negatif)\\n- \"dan parahnya\" (negatif)\\n- \"keterangan pengiriman barang dikembalikan pembeli menolak\" (negatif)\\n- \"ini konsepnya untung cod bayar pakai transfer rugi customer\" (negatif)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
              "berikut adalah analisis sentimen untuk setiap input:\\n\\n1. senang - positif\\n2. belanja - (netral, namun dapat dianggap positif karena seringkali terkait dengan kegiatan yang menyenangkan)\\n3. shopee - (netral, karena merupakan nama platform belanja)\\n4. gratis - positif\\n5. ongkirnya - positif\\n6. pengiriman - positif\\n7. cepat - positif\\n8. sayang - (netral, namun dapat dianggap positif karena seringkali terkait dengan perasaan yang baik)\\n9. toko - (netral, karena merupakan nama toko)\\n10. amanah - positif\\n11. pesan - (netral, karena merupakan kata kerja)\\n12. barang - (netral, karena merupakan kata benda)\\n13. bagus - positif\\n14. kirimnya - positif\\n15. bagus - positif\\n16. mengecewakan - negatif\\n17. semoga - (netral, namun dapat dianggap positif karena seringkali terkait dengan harapan yang baik)\\n18. kedepan - (netral, karena merupakan kata benda)\\n19. lbh - (netral, karena merupakan singkatan dari \"lebih\")\\n20. toko - (netral, karena merupakan nama toko)\\n21. nakal - negatif\\n\\nDengan demikian, sentimen global dari input tersebut dapat dianggap positif karena kata-kata positif seperti \"senang\", \"gratis\", \"ongkirnya\", \"pengiriman\", \"cepat\", \"amanah\", \"bagus\", \"bagus\", \"semoga\" lebih dominan daripada kata-kata negatif seperti \"sayang\", \"mengecewakan\", dan \"nakal\".       1\n",
              "Berikut adalah analisis sentimen untuk setiap kalimat:\\n\\n1. \"shopee aneh barang sesuai pesan\" - positif\\n2. \"kirim dikasih nilai bintang\" - positif\\n3. \"apus toko\" - negatif\\n4. \"produk negeri\" - positif\\n5. \"order mengecewakan\" - negatif\\n6. \"produk lokal kacau\" - negatif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
              "Saya dapat mengategorikan setiap kalimat menjadi positif atau negatif:\\n\\n1. admin sekedar masukan \\n- (positif)\\n\\n2. penilaian tokobarang tertera tanggal \\n- (positif)\\n\\n3. toko pelayanan maksimal \\n- (positif)\\n\\n4. penilaian konsumen membantu \\n- (positif)\\n\\n5. berdasarkan tanggal terbaru penilaian shopee \\n- (positif)\\n\\n6. fitur memfilter tanggal terbaruterlama \\n- (negatif)\\n\\n7. konsumen penilaian shopee ragu \\n- (negatif)\\n\\n8. pembelian minim \\n- (negatif)\\n\\n9. informasi terbaru \\n- (positif)\\n\\n10. kolom penilaian \\n- (positif)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
              "positif, negatif, positif, negatif, negatif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
              "Name: count, Length: 422, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengecek keluaran hasil analisis sentimen\n",
        "df['polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Menyeragamkan output\n",
        "df['polarity'] = df['polarity'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Visualisasi Analisis Sentimen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "sizes = [count for count in df[\"polarity\"].value_counts()]\n",
        "labels = list(df[\"polarity\"].value_counts().index)\n",
        "explode = (0.1, 0, 0)\n",
        "ax.pie(\n",
        "    x=sizes,\n",
        "    labels=labels,\n",
        "    autopct=\"%1.2f%%\",\n",
        "    textprops={\"fontsize\": 14},\n",
        ")\n",
        "ax.set_title(f\"Sentiment Polarity on df Data \\n (total = {len(df)} df)\", fontsize=16, pad=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "positive_reviews = df[['text_akhir','polarity']].loc[df['polarity'] == 'positif']\n",
        "negative_reviews = df[['text_akhir','polarity']].loc[df['polarity'] == 'negatif']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi Word Cloud\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 10))\n",
        "\n",
        "# Word Cloud pada review positif\n",
        "list_postive_reviews = \"\"\n",
        "for row_word in positive_reviews.iloc[:, 0]:\n",
        "    list_postive_reviews += \" \" + (row_word)\n",
        "wordcloud_positive = WordCloud(\n",
        "    width=800, height=600, background_color=\"black\", colormap=\"Greens\", min_font_size=10\n",
        ").generate(list_postive_reviews)\n",
        "ax[0].set_title(\n",
        "    \"Word Cloud of Positive Reviews\",\n",
        "    fontsize=14,\n",
        ")\n",
        "ax[0].grid(False)\n",
        "ax[0].imshow((wordcloud_positive))\n",
        "fig.tight_layout(pad=0)\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "# Word Cloud pada review negatif\n",
        "list_negative_reviews = \"\"\n",
        "for row_word in negative_reviews.iloc[:, 0]:\n",
        "    list_negative_reviews += \" \" + (row_word)\n",
        "wordcloud_negative = WordCloud(\n",
        "    width=800, height=600, background_color=\"black\", colormap=\"Reds\", min_font_size=10\n",
        ").generate(list_negative_reviews)\n",
        "ax[1].set_title(\n",
        "    \"Word Cloud of Negative Reviews\",\n",
        "    fontsize=14,\n",
        ")\n",
        "ax[1].grid(False)\n",
        "ax[1].imshow((wordcloud_negative))\n",
        "fig.tight_layout(pad=0)\n",
        "ax[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAZsjOqBcGn2"
      },
      "source": [
        "## 5. Ekstraksi Fitur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def makeReviewDict(series):\n",
        "    words = dict()\n",
        "    for row in series:\n",
        "        texts = row.split()\n",
        "        for text in texts:\n",
        "            if text not in words:\n",
        "                words[text] = 1\n",
        "            else:\n",
        "                words[text] += 1\n",
        "    return words       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviewDict = makeReviewDict(df['text_akhir'])\n",
        "ln = df['text_akhir'].apply(lambda x: len(x)).quantile(0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[df['polarity']!='netral']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ekstraksi Fitur dengan embedding\n",
        "num_words = 6000\n",
        "tokenizer = Tokenizer(num_words=num_words) \n",
        "tokenizer.fit_on_texts(df['text_akhir'])\n",
        "X = tokenizer.texts_to_sequences(df['text_akhir'])\n",
        "X = pad_sequences(X, maxlen=150, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mengubah tipe data string menjadi biner, 0 untuk negative dan 1 untuk positive\n",
        "y = df['polarity'].apply(lambda x: 1 if x == 'negatif' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_temp, X_test, y_temp, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Model Building\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words, X_train.shape[1])) # Mengubah indeks integer (kata) menjadi vektor dense\n",
        "    model.add(SpatialDropout1D(0.2)) # Dropout khusus data sekuensial seperti teks\n",
        "    # model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "    model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2))\n",
        "    # model.add(Dense(128, activation='relu'))\n",
        "    # model.add(BatchNormalization())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Model Testing\n",
        "print(f'Akurasi test data\\t: {model.evaluate(X_test,y_test)[1]*100:.2f} %')\n",
        "print(f'Akurasi train data\\t: {model.evaluate(X_train, y_train)[1]*100:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fungsi untuk membuat model\n",
        "# def build_model(hp):\n",
        "#     # model = Sequential()\n",
        "#     # # Hyperparameter jumlah neuron pada layer pertama\n",
        "#     # model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
        "#     #                 activation=hp.Choice('activation_1', values=['relu', 'tanh', 'sigmoid']),\n",
        "#     #                 input_dim=20))  # Misalnya 20 fitur pada data input\n",
        "\n",
        "#     # # Hyperparameter jumlah neuron pada layer kedua (opsional)\n",
        "#     # model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=256, step=32),\n",
        "#     #                 activation=hp.Choice('activation_2', values=['relu', 'tanh', 'sigmoid'])))\n",
        "\n",
        "#     # # Output layer\n",
        "#     # model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#     # # Compile model\n",
        "#     # model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop']),\n",
        "#     #               loss='binary_crossentropy',\n",
        "#     #               metrics=['accuracy'])\n",
        "    \n",
        "#     model.add(Embedding(num_words, X_train.shape[1])) # Mengubah indeks integer (kata) menjadi vektor dense\n",
        "#     model.add(SpatialDropout1D(0.3)) # Dropout khusus data sekuensial seperti teks\n",
        "#     model.add(LSTM(units=hp.Int('units_1', min_value=32, max_value=64, step=16), \n",
        "#                    dropout=0.3, recurrent_dropout=0.3))\n",
        "#     model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=64, step=16),\n",
        "#                     activation=hp.Choice('activation_1', values=['relu', 'tanh', 'sigmoid']),\n",
        "#                     input_dim=20)) \n",
        "#     model.add(Dense(1, activation='sigmoid'))\n",
        "#     model.compile(optimizer=RMSprop(learning_rate=0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# # Definisikan tuner\n",
        "# tuner = Hyperband(\n",
        "#     build_model,\n",
        "#     objective='val_accuracy',  # Tujuan optimasi\n",
        "#     max_epochs=10,             # Maksimal jumlah epoch\n",
        "#     factor=3,                  # Faktor reduksi pada Hyperband\n",
        "#     directory='my_dir',        # Direktori untuk menyimpan hasil tuning\n",
        "#     project_name='hyperparameter_tuning'\n",
        "# )\n",
        "\n",
        "# # Callback untuk early stopping\n",
        "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# # Lakukan pencarian hyperparameter\n",
        "# tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# # Hasil terbaik\n",
        "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "# print(f\"Best Hyperparameters: {best_hps.values}\")\n",
        "\n",
        "# # Buat model dengan hyperparameter terbaik\n",
        "# model = tuner.hypermodel.build(best_hps)\n",
        "# history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "# # Evaluasi model\n",
        "# loss, accuracy = model.evaluate(X_train, y_train)\n",
        "# print(f\"Final Accuracy: {accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
